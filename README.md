# âš™ï¸data-forge-lab
DataForgeLab is an experimental platform designed to explore and master data engineering concepts. This project aims to simulate real-world data processing scenarios.
This project is a personal data management and productivity tracker that allows users to log habits, events, and self-development metrics. It's built using Onion Architecture and a microservice-friendly design.

# âš ï¸ Disclaimer

This project is currently **under active development** and serves primarily as a personal sandbox for experimentation and learning.

- Many components are not production-ready.
- The codebase may lack standard production features such as input validation, error handling, and security hardening.
- Some architectural choices may evolve or be restructured.

Feedback and contributions are welcome as the project matures!

# ğŸš€ Tech Stack:
- Frontend: React
- Backend: Python (Flask)
- Database: MongoDB (also supports in-memory repo)
- Microservices: Go (notifications, analytics)
- Messaging: Kafka (event publishing + consumption)

# ğŸ§° How to get started:

To get the project up and running, follow these steps:

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/sayanel/data-forge-lab
    cd data-forge-lab
    ```

2.  **Set up the Python virtual environment:**
    ```bash
    # For Windows
    python -m venv venv
    .\venv\Scripts\activate

    # For macOS and Linux
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Install backend dependencies:**
    With the virtual environment activated, install the required Python packages:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set up environment variables:**
    - Edit the `.env` file with your specific configuration. Most likely you will just have to replace the IP to reach Kafka, that is running in wsl2.
    - Go through the batch file in the bin directory and potentially change paths to mongo and kafka.

5.  **Run the application:**
    Navigate to the bin directory.
    Start:
      - start_mongo.bat
      - kafka/start_kafka.bat
      - start_app.bat
      - start_front.bat
      - start_microservices.bat (optional)

---
# ğŸ§± Project Architecture Overview


## ğŸ§  Key Concepts:
- Person: A user entity
- Habit: A recurring activity
- HabitEvent: A tracked occurrence of a habit
- HabitEventCreatedMessage: A Kafka DTO published when a habit event is logged

    
## ğŸ—ºï¸ Hierarchy
This project is structured using a **clean, layered architecture** based on principles from **Onion** and **Hexagonal Architecture**. The goal is to keep the core logic independent from external concerns like databases, APIs, or frameworks, making the application modular, testable, and maintainable.

- application/
    - domain/ â†’ core models â†’ business entities
    - domain / â†’ services â†’ business logic/rules
    - use_cases/ â†’ orchestrates domain services and repo
- infrastructure/ â†’ adapters
    - persistence/ â†’ MongoDB + in-memory adapters
    - messaging/ â†’ Kafka publisher/consumer
    - config/ â†’ system-level setup
- interfaces/ â†’ framework adapters
    - controllers/ â†’ API layer â†’ REST entry points with Flask
    - repositories/ â†’ interfaces for persistence (used by services)
- microservices/
    - analytics, notifications, etc.


## ğŸ§­ Responsibilities

### `application/domain/models` - **Domain Models**

**Purpose:**  
These are the core entities of the system - like `Habit`, `Person`, and `HabitEvent`. They represent real-world concepts and are central to the business logic.

**Characteristics:**
- Pure Python classes or dataclasses
- Represent state and simple behavior
- No dependencies on infrastructure or frameworks

---

### `application/domain/services` - **Domain Services**

**Purpose:**  
Encapsulate core business logic and rules that span multiple entities.

**Characteristics:**
- Contains essential logic (e.g., calculating a streak)
- Interacts with domain models
- No direct dependencies on databases, APIs, or external systems

**Example:**  
Updating habit status, checking if a goal has been achieved, or publishing an event.

---

### `application/use_cases` - **Application Use Cases**

**Purpose:**  
Orchestrate domain services and repositories to fulfill a specific application-level goal (i.e., user stories).

**Characteristics:**
- Define workflows (e.g., create habit event, get user habits)
- Coordinate between domain and infrastructure
- Handle application-specific decisions

---

### `interfaces/repositories` - **Repository Interfaces**

**Purpose:**  
Abstract the data access layer so the domain logic doesn't need to know how data is stored or retrieved.

**Example:**
```python
class HabitRepository(Protocol):
    def save(self, habit: Habit) -> Habit: ...
    def get(self, habit_id: UUID) -> Habit: ...
```

---

### `infrastructure/persistence` - **Data Layer Implementations**

**Purpose:**  
Implements the repository interfaces using actual persistence technologies like MongoDB or in-memory storage.

**Characteristics:**
- Swappable (e.g., test vs prod)
- Isolated from business logic
- Bound via dependency injection

---

### `interfaces/controllers` - **API Layer (Flask)**

**Purpose:**  
Expose application features via RESTful APIs. It receives HTTP requests, translates them into use case calls, and returns responses.

**Responsibilities:**
- Input/output transformation
- Calls into the application layer
- Stateless and thin - no business logic

---

### `infrastructure/messaging` - **Kafka Messaging (Pub/Sub)**

**Purpose:**  
Handle asynchronous events with Kafka. Used for emitting and consuming domain events (like `HabitEventCreated`).

**Components:**
- **Publisher:** Emits messages to Kafka topics
- **Consumer:** Listens to topics and reacts (e.g., triggers a notification)

**Why here:**  
Messaging is infrastructure - we isolate it from core logic and inject it via interfaces.

---

### `infrastructure/config` - **Configuration Layer**

**Purpose:**  
System-wide setup: MongoDB config, Kafka topics, environment variable bindings, etc.

**Characteristics:**
- Keeps config centralized
- Keeps other layers clean and decoupled

---

### `microservices/` - **Event-Driven Sidecar Services**

**Purpose:**  
Independent microservices that listen to Kafka and perform specific actions like notifications or analytics.

**Examples:**
- `simulate`: Simulates user behavior for testing
- `notifications`: Sends alerts when certain events occur
- `analytics`: Gathers and processes behavioral metrics

---

## ğŸ”„ Layer Interactions

**Key Design Principles:**

- **Dependency Inversion:**  
  The core domain doesn't depend on infrastructure. Instead, it defines abstract interfaces (e.g., repository contracts).

- **Abstraction:**  
  Repositories are interfaces defined in the domain or adjacent layers, with implementations in `infrastructure`.

- **Separation of Concerns:**  
  Each layer has a clearly defined role, making the system easier to test, maintain, and extend.

---


## ğŸ“ Project Directory Structure

```plaintext
data_forge_lab/
â”œâ”€â”€ application/
â”‚   â”œâ”€â”€ use_cases/
â”‚   â”‚   â”œâ”€â”€ habit_event_use_cases.py
â”‚   â”‚   â”œâ”€â”€ habit_use_cases.py
â”‚   â”‚   â””â”€â”€ person_use_cases.py
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ event.py
â”‚   â”‚   â”‚   â”œâ”€â”€ habit.py
â”‚   â”‚   â”‚   â””â”€â”€ person.py
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ habit_event_service.py
â”‚   â”‚       â”œâ”€â”€ habit_service.py
â”‚   â”‚       â””â”€â”€ person_service.py
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ habit_categories.py
â”‚   â”‚   â””â”€â”€ mongo_config.py
â”‚   â”œâ”€â”€ persistence/
â”‚   â”‚   â”œâ”€â”€ mongodb/
â”‚   â”‚   â”‚   â”œâ”€â”€ habit.py
â”‚   â”‚   â”‚   â”œâ”€â”€ habit_event.py
â”‚   â”‚   â”‚   â””â”€â”€ person.py
â”‚   â”‚   â””â”€â”€ in_memory.py
â”‚   â””â”€â”€ messaging/        # Kafka-related publisher/consumer logic
â”œâ”€â”€ interfaces/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ habit_controller.py
â”‚   â”‚   â”œâ”€â”€ habit_event_controller.py
â”‚   â”‚   â””â”€â”€ person_controller.py
â”‚   â””â”€â”€ repositories/
â”‚       â”œâ”€â”€ habit_event_repository.py
â”‚       â”œâ”€â”€ habit_repository.py
â”‚       â””â”€â”€ person_repository.py
â”œâ”€â”€ microservices/        # Event-driven side services
â”œâ”€â”€ frontend/             # React-based UI
â”œâ”€â”€ tests/                # Unit and integration tests
â”œâ”€â”€ .env                  # Environment configuration
â”œâ”€â”€ app.py                # Main entry point (Flask)
â”œâ”€â”€ containers.py         # Dependency Injection setup
â””â”€â”€ venv/                 # Virtual environment
````

# ğŸ“¬ Kafka
Requirements:
- WSL installed and working
- Kafka downloaded and extracted inside ~/kafka/kafka_2.13-4.0.0 inside WSL
- All commands assume Kafka default port localhost:9092
Domain Services (domain/services)


Purpose: Domain services contain the core business logic and rules of your application. They encapsulate behaviors that involve multiple domain entities or complex business processes that don't naturally fit within a single entity.
